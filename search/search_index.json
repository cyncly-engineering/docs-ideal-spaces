{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Ideal Spaces","text":""},{"location":"#overview","title":"Overview","text":"<p>All information related to Ideal Spaces 7 </p> <p></p>"},{"location":"Datadog/datadog%20in%20LMFR%20prod/","title":"Datadog in LMFR prod","text":""},{"location":"Datadog/datadog%20in%20LMFR%20prod/#important-links","title":"Important links","text":"<ol> <li>LMFR Dashbroad</li> </ol> <ol> <li>LMFR traces</li> <li>Logs</li> <li>Logs error outlier</li> <li>Monitoring</li> <li>Application security</li> </ol>"},{"location":"Datadog/datadog%20in%20LMFR%20prod/#upcoming-tasks","title":"Upcoming tasks","text":"<ol> <li> <p>Alerting on what matters     a. send alert when a particular issue occured x times in a specific timeframe.</p> </li> <li> <p>Investigating performance issues </p> </li> <li>Scaling events &amp; alerts </li> </ol>"},{"location":"Datadog/datadog%20in%20LMFR%20prod/#available-features-in-datadog-platform","title":"Available features in Datadog platform","text":"<ol> <li> <p>Integration</p> <p>a. Azure DevOps </p> <p>c. MS Team </p> <p>Datadog Connector is added in MS Team</p> <p>d. SSO with SAML </p> </li> <li> <p>Infrastructure</p> <p>a. Azure severless </p> <p>b. Agent </p> <p>c. Univeral service monitoring </p> </li> <li> <p>Metrics </p> <p>a. Custom metrics </p> </li> <li> <p>Logs ingestion </p> <p>a. Rentention policy </p> <p>b. Archived policy </p> <p>c. Rotation policy </p> </li> <li> <p>APM  </p> <p>a. Connect traces with RUM </p> <p>b. Connect traces with logs </p> </li> <li> <p>UX Monitoring </p> <p>a. Real User Monitoring </p> <p>b. API Synthetic Monitoring </p> <p>c. Browser Synthetic Monitoring  </p> </li> <li> <p>Security </p> <p>a. Application security </p> <p>b. Cloud SIEM </p> </li> <li> <p>SLIs/SLOs </p> <p>a. Uptime/online monitoring  </p> <p>b. Availability/Counter metrics based SLOs </p> <p>c. Latency/Monitoring based SLOs </p> </li> <li> <p>Dashboards </p> <p>a. Organizational overview </p> <p>b. LMFR prod dashboard </p> </li> <li> <p>Monitoring </p> <p>a. Watchdog </p> <p>b. Anomaly detection  </p> <p>For example:  service response rate 100% 5xx errors - this might indicates that the service is offline. should send a notification</p> <p>c. Metrics forecast </p> <p>d. Outlier detection </p> <p>e. Forecast monitoring  </p> <p>For example:  requests rate &gt;= 20; should get alerts  or; logs filling up fast, alert a week before for rotation policy  or; forecast biz KPIs</p> <p>f. Manage downtime </p> </li> <li> <p>Working with incident - declare incident, publish postmortem </p> </li> <li> <p>Dora metric reporting </p> </li> <li> <p>Best practises</p> <p>a. Tagging resources </p> <p>b. Org/Datadog tag policy </p> </li> </ol>"},{"location":"Datadog/datadog%20in%20LMFR%20prod/#resources","title":"Resources","text":"<p>Gabriel, Robert, Pandurang, Siddhesh, Jestha</p>"},{"location":"Datadog/datadog%20in%20LMFR%20prod/#service-availability-definitions","title":"Service Availability Definitions","text":"<p>In Order to calculate the availability of the service, three indicators are taken into account.</p> <ol> <li>The service is available.</li> <li>The service is online.</li> <li>The service response time is under the defined latency</li> </ol> <p>This indicators will consider the following major features/functions:</p> <ol> <li>Login</li> <li>Creation of a design/project</li> <li>Search for a design/project</li> <li>Load a design/project</li> <li>Save a design/project</li> <li>Display pricing</li> <li>Retrieve item list for design/project</li> </ol> <p>Indicator 1 - Availability Calculation = SR1 / TR1 for each major function listed above </p> <p>SR1 = Total # of Requests in the Reporting Period with an http response code below 500</p> <p>TR1 = Total # of Requests in Reporting Period</p> <p>Indicator 2 - Online Calculation = SR2 / TR2 for synthetic requests to be defined(see section Yearly review)</p> <p>SR2 = Total # of Requests in Reporting Period with an http response code below 400</p> <p>TR2 = Total # of Requests in Reporting Period</p> <p>Indicator 3 - Latency The latency calculation is to be defined(see section Yearly review)</p> <p>Overall Service Availability Calculation = For a given period of time, the Service availability will always be the lowest availability of the three indicators above.</p>"},{"location":"Datadog/datadog%20in%20LMFR%20prod/#status-of-features-available","title":"Status of features available","text":"<p>IS 7 map</p>"},{"location":"Datadog/evaluation%20notes/","title":"Evaluation notes","text":""},{"location":"Datadog/evaluation%20notes/#evaluation","title":"Evaluation","text":""},{"location":"Datadog/evaluation%20notes/#notes","title":"Notes","text":"<ol> <li>Azure Event hub usage and cost needs to be tracked </li> <li>Disable Application insights and hence no new entries in AZ Log analytics </li> <li>Any services or reporting build on top of Log analytics will be broken </li> <li>Duplicate Persistant of logs is not a valid concerns </li> <li>if you want to send resource and activity logs you can run the automated install form here to automatically set up an event hub in your Azure account to collect these logs and have them forwarded to DD. https://docs.datadoghq.com/logs/guide/azure-logging-guide/?tab=automatedinstallation This will give further info on the Web Apps/Functions themselves from an infrastructure perspective</li> <li>Need to have organization\u2019s tag policies https://docs.datadoghq.com/monitors/settings/#tag-policies</li> </ol>"},{"location":"Datadog/evaluation%20notes/#azure-integration-for-enabling-apm","title":"Azure integration for enabling APM","text":""},{"location":"Datadog/evaluation%20notes/#status-of-features-enable","title":"Status of features enable","text":""},{"location":"Datadog/poc/","title":"Enhance Datadog POC","text":""},{"location":"Datadog/poc/#success-criteria","title":"Success Criteria","text":""},{"location":"Datadog/poc/#estimate-duration-and-effort","title":"Estimate duration and effort","text":""},{"location":"Datadog/poc/#scope-of-poc","title":"Scope of POC","text":"<ol> <li> <p>Integration</p> <p>a. Azure DevOps </p> <p>c. MS Team </p> <p>Datadog Connector is added in MS Team</p> <p>d. SSO with SAML </p> </li> <li> <p>Infrastructure</p> <p>a. Azure severless </p> <p>b. Agent </p> <p>c. Univeral service monitoring </p> </li> <li> <p>Metrics </p> <p>a. Custom metrics </p> </li> <li> <p>Logs ingestion </p> <p>a. Rentention policy </p> <p>b. Archived policy </p> <p>c. Rotation policy </p> </li> <li> <p>APM  </p> <p>a. Connect traces with RUM </p> <p>b. Connect traces with logs </p> </li> <li> <p>UX Monitoring </p> <p>a. Real User Monitoring </p> <p>b. API Synthetic Monitoring </p> <p>c. Browser Synthetic Monitoring  </p> </li> <li> <p>Security </p> <p>a. Application security </p> <p>b. Cloud SIEM </p> </li> <li> <p>SLIs/SLOs </p> <p>a. Uptime monitoring  </p> <p>b. Metrics based SLOs </p> <p>c. Monitoring based SLOs </p> </li> <li> <p>Dashboards </p> <p>a. Organizational overview </p> <p>b. Product/service dashboard </p> </li> <li> <p>Monitoring </p> <p>a. Watchdog </p> <p>b. Anomaly detection  </p> <p>For example:  service response rate 100% 5xx errors - this might indicates that the service is offline. should send a notification</p> <p>c. Metrics forecast </p> <p>d. Outlier detection </p> <p>e. Forecast monitoring  </p> <p>For example:  requests rate &gt;= 20; should get alerts  or; logs filling up fast, alert a week before for rotation policy  or; forecast biz KPIs</p> <p>f. Manage downtime </p> </li> <li> <p>Working with incident - declare incident, publish postmortem </p> </li> <li> <p>Dora metric reporting </p> </li> <li> <p>Best practises</p> <p>a. Tagging resources </p> <p>b. Org/Datadog tag policy </p> </li> </ol>"},{"location":"Datadog/poc/#resources","title":"Resources","text":"<p>Gabriel, Pandurang, Siddhesh, Jestha</p>"},{"location":"Datadog/poc/#service-availability-definitions","title":"Service Availability Definitions","text":"<p>In Order to calculate the availability of the service, three indicators are taken into account.</p> <ol> <li>The service is available.</li> <li>The service is online.</li> <li>The service response time is under the defined latency</li> </ol> <p>This indicators will consider the following major features/functions:</p> <ol> <li>Login</li> <li>Creation of a design/project</li> <li>Search for a design/project</li> <li>Load a design/project</li> <li>Save a design/project</li> <li>Display pricing</li> <li>Retrieve item list for design/project</li> </ol> <p>Indicator 1 - Availability Calculation = SR1 / TR1 for each major function listed above </p> <p>SR1 = Total # of Requests in the Reporting Period with an http response code below 500</p> <p>TR1 = Total # of Requests in Reporting Period</p> <p>Indicator 2 - Online Calculation = SR2 / TR2 for synthetic requests to be defined(see section Yearly review)</p> <p>SR2 = Total # of Requests in Reporting Period with an http response code below 400</p> <p>TR2 = Total # of Requests in Reporting Period</p> <p>Indicator 3 - Latency The latency calculation is to be defined(see section Yearly review)</p> <p>Overall Service Availability Calculation = For a given period of time, the Service availability will always be the lowest availability of the three indicators above.</p>"},{"location":"Postmortem/postmortem/","title":"Ideal Spaces 6 postmortem(#incident Bug 622695)","text":""},{"location":"Postmortem/postmortem/#date-2023-09-27","title":"Date : 2023-09-27","text":""},{"location":"Postmortem/postmortem/#authors-om-pandurang-siddhesh-sagar-sanketkumar-benoit-jestha","title":"Authors: Om, Pandurang, Siddhesh, Sagar, Sanketkumar, Benoit, Jestha","text":""},{"location":"Postmortem/postmortem/#status","title":"Status","text":"<p>Complete, action items are in progress</p>"},{"location":"Postmortem/postmortem/#summary","title":"Summary","text":""},{"location":"Postmortem/postmortem/#impact","title":"Impact","text":"<p>Estimated x millions queries lost, $x revenue impact * End user Impact * Infrastructure impact * Productivity impact </p>"},{"location":"Postmortem/postmortem/#root-causes","title":"Root Causes","text":"<p>Cascading failure due to combination of profiler production IS 6 applications and exceptionally  CPU intensive catalog search failed operation triggered. Under normal circumstances, the rate of task failure due to catalog search failure is low enough to be unnoticed. </p>"},{"location":"Postmortem/postmortem/#trigger","title":"Trigger","text":"<p>PCS triggered CIC Decor cabinet catalogue by sudden increase CPU peak and combination of application insights profiler runs for 2 mins per every hour</p>"},{"location":"Postmortem/postmortem/#resolution","title":"Resolution","text":"<p>Disabled profiler and deactivated CIC Decor Cabinet catalog to mitigate the cascading failure.</p>"},{"location":"Postmortem/postmortem/#detection","title":"Detection","text":"<p>Traces are investingate, found many HTTP requests execution time take over 40 mins and 3x slow TCP wait time </p> <p>Detected high level of HTTP 500x </p>"},{"location":"Postmortem/postmortem/#action-items","title":"Action Items","text":"<ul> <li>Disabled profiler</li> <li>Deactivated CIC Decor Cabinates catalog</li> <li>Increase visibility</li> <li>Review scale out rule </li> <li>Detect IP triggers CIC Decor Cabinet catalog</li> <li>Define SLO/SLI - identify catalog that bringing issue</li> <li>Review architecture - Workload distributed via CDN Frontdoor</li> <li>~~Comms via MS Team and email~~</li> <li>Add Kusto query in workbook </li> </ul>"},{"location":"Postmortem/postmortem/#lessons-learned","title":"Lessons Learned","text":""},{"location":"Postmortem/postmortem/#what-went-well","title":"What went well","text":""},{"location":"Postmortem/postmortem/#what-went-wrong","title":"What went wrong","text":"<p>~~No alerts or; alerts triggered but those information are lost due to noise~~ ~~Failure of anomalies detection~~ High discovery time Application failure of fail fast and safely</p>"},{"location":"Postmortem/postmortem/#where-we-got-lucky","title":"Where we got lucky","text":""},{"location":"Postmortem/postmortem/#timeline","title":"Timeline","text":"<p>2023-09-21 (all times in UTC)</p> <ul> <li>2023-09-15 13:32 Enabled application insights profiler</li> <li>2023-09-15 ??:?? OUTAGE BEGINS Loading catalogs information and search backends start metling down under load</li> <li>2023-09-19 08:37 INCIDENT BEGINS Bug 622695 incident reported by customer support team.</li> <li>2023-09-20 ??:?? Disabled application insights profiler for product offering</li> <li>2023-09-22 06:07 OUTAGE MITIGATED Deactivated CIC Decor Cabinets catalog </li> <li>??:?? ~~HTTP errors rates remain within SLO?~~ No task failure observed </li> <li>??:?? INCIDENT ENDS reached average CPU 60% and maximum CPU 95% with nominal performance </li> <li>??:?? OUTAGE ENDS all upstream requests are responsed in milliseconds </li> <li>2023-09-25 10:46 ~~Jestha wrote email to Joris CSM~~ INCIDENT ENDS Confirmed IS 6 application performance is back to normal</li> </ul>"},{"location":"Postmortem/postmortem/#supporting-information","title":"Supporting information","text":""},{"location":"architecture/","title":"Architecture","text":"<p>All things in wider range of architecture. </p>"},{"location":"architecture/api_principles/","title":"Principles of our APIs","text":""},{"location":"architecture/api_principles/#url-scheme","title":"URL Scheme","text":"<ul> <li>We use plurals for our resource names, e.g. <code>projects</code>, <code>features</code>, <code>items</code></li> <li>We use URL-friendly names for paths and query parameter with lower case and hyphens for spaces (kebab-case / spinal-case, as recommended for example here), e.g. <code>feature-item-number</code></li> <li>Mandatory parameters are in the path</li> <li>Other parameter to filter a search are query parameters in the URL</li> <li>Searches get a path prefix <code>search</code>, e.g.<ul> <li><code>/feature-items/search/item-id/1</code> </li> <li><code>/tenants/search/user-id/1?creation-date-time-from=2020-05-30TT10:36:00+00:00</code> </li> </ul> </li> </ul>"},{"location":"architecture/api_principles/#responses","title":"Responses","text":""},{"location":"architecture/api_principles/#http-status-codes","title":"HTTP status codes","text":"<p>We use HTTP status codes to indicate successful or erroneous requests.</p>"},{"location":"architecture/api_principles/#successful-responses","title":"Successful responses","text":"<p>If the resource / data is found and everything is fine, we return the data in a wrapping JSON object  with the property <code>result</code> containing the actual object. This enables us to add other metadata later on.</p>"},{"location":"architecture/api_principles/#single-result","title":"Single result","text":"<p>The result property contains a single object.</p> <p>Either we return a successful status with the data (http status 2xx), or a 404 Not Found if no data was found.</p> <p>```json title=\"Example\" {   \"result\": {     \"itemId\": 1,     \"projectId\": \"P-1\",     \"... other fields...\": \"\"   } }</p> <pre><code>\n#### Multiple results\n\nThe result property contains an array of objects.\n\nWe always return a successful status with the data (http status 2xx), the array will be empty if no data was found.\n\nWe include this metadata:\n\n* `resultItemCount`: Allows the consumer to quickly assess the result\n* `totalItemCount`: Allows the consumer to properly use the pagination later on (to set limit/offset accordingly)\n\n```json title=\"Example\"\n{\n  \"result\": [\n    {\n      \"itemId\": 1,\n      \"projectId\": \"P-1\",\n      \"... other fields...\": \"\"\n    },\n    {\n      \"itemId\": 11,\n      \"projectId\": \"P-1\",\n      \"... other fields...\": \"\"\n    }\n  ],\n  \"resultItemCount\": 2,  \n  \"totalItemCount\": 2  \n}\n</code></pre>"},{"location":"architecture/api_principles/#non-successful-responses","title":"Non-successful responses","text":"<p>There are different kinds of non-successful responses: A resource might still be in a wrong state (informative), a validation error happens, ...</p> <p>These errors are all JSON data, they contain</p> <ul> <li>a <code>key</code> that is used by machines (other services) to interpret the kind of error</li> <li>a general <code>description</code> about the error in English so a human can read/identify it in logs/debugging; Not to be used / interpreted by machines/services</li> <li>a <code>trace id</code> to allow us/others to look at the logs (trace-ID header generated by router?? api-gateway??)</li> <li>if multiple errors can occur, they are wrapped in an array</li> </ul> <p>```json title=\"Single error\" {   \"key\": \"error.validation.ABC\",   \"description\": \"Not so good\",   \"trace-id\": \"....\" }</p> <pre><code>\n```json title=\"Multiple errors\"\n{\n  \"errors\": [\n    {\n      \"key\": \"error.validation.ABC\",\n      \"description\": \"Not so good\",\n    },\n    {\n      \"key\": \"error.validation.YXZ\",\n      \"description\": \"Worse\",\n    },\n  ],\n  \"trace-id\": \"....\"\n}\n</code></pre>"},{"location":"architecture/api_principles/#informative-responses","title":"Informative responses","text":"<p>Sometimes we cannot (yet) return the requested object as it is in the wrong state.  For example a project was submitted by designer, but not yet processed by IS backend.</p> <p>In these cases, the <code>key</code> is prefixed with <code>info.</code>.</p> <p>```json title=\"Example\" {   \"key\": \"info.accepted\",   \"description\": \"Project creation request has been accepted but has not yet completed\",   \"trace-id\": \"....\" }</p> <pre><code>\n#### General errors\n\nThe consumer should usually make sure that all requirements for creating a project are satisfied (e.g. ), but still sometimes something could happen.\n\n```json title=\"Example\"\n{\n  \"key\": \"error.project_not_created\",\n  \"description\": \"option id? not found\",\n  \"trace-id\": \"....\"\n}\n</code></pre>"},{"location":"architecture/api_principles/#validation-errors","title":"Validation errors","text":"<p>When creating resources (project, feature, ...) we validate the incoming request.</p> <p>In these cases, the <code>key</code> is prefixed with  <code>error.validation.</code>, and the response contains more information about the issue and which field is affected.</p> <p><code>json title=\"Example\" {   \"key\": \"error.validation.min_length\",   \"description\": \"Field value is too short, expected '&gt;= 2', was '1'\",   \"fieldName\": \"featureName\",   \"fieldValue\": \"E\",   \"checkValue\": \"2\",   \"trace-id\": \"....\" }</code></p>"},{"location":"architecture/platform-health/","title":"Platform Health","text":""},{"location":"architecture/platform-health/#objective","title":"Objective","text":"<p>Provide visibility of planned work that Ideal Space 7 team need to do (and are already doing) in order to keep our platforms running and meet our (contractual and moral) obligations to the business, our users and customers.</p>"},{"location":"architecture/platform-health/#key-result","title":"Key result","text":"<p>Teams include this type of work on documents in a way that can be discussed, understood and effectively prioritised as an integral part of work in our focus areas.</p>"},{"location":"architecture/platform-health/#categories","title":"Categories","text":""},{"location":"architecture/platform-health/#buildable","title":"Buildable","text":"<ul> <li>It can be built via a build triggered by Git commits on a supported CI platform (generally Azure pipeline)<ul> <li>This will need to be checked regularly, as environmental changes (including external) can alter this at any time</li> </ul> </li> <li>It can be built in a reproducible manner (considering Docker Compose or Docker could be better option)</li> <li>The build will test and report on constraints (e.g. it\u2019ll tell you if you are trying to build it with the wrong version of .NET framework)</li> <li>Where practical, the build can be run locally (without Docker) if the dependencies exist - this is to make development more convenient, but may be challenging or even impossible for applications with complex dependencies</li> <li>It should be buildable via a script called 'build' (or 'do-build' where build is blocked by framework, e.g. React)</li> <li>Upstream applications should provide a known QA environment which can be used by dependants for testing</li> </ul>"},{"location":"architecture/platform-health/#deployable","title":"Deployable","text":"<ul> <li>It can be deployed to a supported environment (e.g. Azure app service)<ul> <li>This will need to be checked regularly, as environmental changes (including external) can alter this at any time</li> </ul> </li> <li>The deployment is done automatically after the CI build passes</li> <li>Smoke testing is in place to ensure the deployment is working</li> <li>Consumer-Driven Contracts (CDC) are in place to test that dependencies are compatible</li> <li>No manual action is required during the deployment, i.e. the deployment should not be gated</li> <li>The application can be terminated or suspended on demand in case of critical issues (e.g. data leaks)<ul> <li>E.g. a <code>az webapp stop</code> is fine, as long as it leaves the system in a safe, restartable state (e.g. no data corruption is caused by the shutdown method)</li> <li>This may require documentation where a service cannot simply be stopped safely</li> <li>Where users need to be informed that this page/service is currently not available, it might be necessary to have a maintenance page application at hand which then is deployed on the route(s) of the stopped application.</li> </ul> </li> </ul>"},{"location":"architecture/platform-health/#secure","title":"Secure","text":"<ul> <li>Dependencies are kept up to date</li> <li>Automatic scanning is in place (e.g. Contrast, GitHub dependency checks, Snyk, \u2026)</li> <li>Any known exploitable issues are resolved as a matter of urgency</li> </ul>"},{"location":"architecture/platform-health/#performant","title":"Performant","text":"<ul> <li>It has defined objectives for performance - this is particularly critical where there are clients of this application with their own objectives</li> <li>The performance is monitored and significant changes are corrected</li> </ul>"},{"location":"architecture/platform-health/#scalable","title":"Scalable","text":"<ul> <li>The applications scale to meet the capacity requirements forecast for the medium-term</li> </ul>"},{"location":"architecture/platform-health/#observable","title":"Observable","text":"<ul> <li>Critical metrics are captured for the application via the supported monitoring platforms<ul> <li>The nature of these metrics will depend on the application</li> <li>Alongside runtime metrics these may also include code and other non-functional metrics that contribute to maintaining and supporting the application</li> </ul> </li> <li>Error information is captured via supported tools (e.g. ApplicationInsights, datadog, Sentry, etc.)</li> </ul>"},{"location":"architecture/platform-health/#accessible","title":"Accessible","text":"<ul> <li>It meets all contractual and legal requirements for accessibility</li> </ul>"},{"location":"architecture/platform-health/#browser-compatibility","title":"Browser Compatibility","text":"<ul> <li>It is compatible with our currently supported set of browsers</li> <li>It is adapted for upcoming changes to supported browsers (e.g. Chrome cookie changes)</li> </ul>"},{"location":"architecture/platform-health/#dependencies","title":"Dependencies","text":"<ul> <li>All dependencies are supported versions and have no known security vulnerabilities</li> <li>Where a dependency is no longer supported mitigations are made (e.g. a branch that we can support) or a migration to a supported alternative is completed</li> </ul>"},{"location":"architecture/platform-health/#understandable","title":"Understandable","text":"<ul> <li>The purpose of applications should be clear, as should the user/business problems it solves</li> <li>It should be possible for a developer to understand the basics of how an application is built and works without requiring a chat with anyone</li> </ul>"},{"location":"architecture/platform-health/#lifecycle","title":"Lifecycle","text":"<ul> <li>An application should have a technical and product owner within Cyncly - including if the app is in C&amp;M or supported by a third party - and this must be documented in the repository's README file</li> <li>If the ownership of the application changes then a handover process must take place, transferring all required knowledge to maintain the application, and the change in ownership must be broadcast to all stakeholders</li> <li>Applications at the end of their useful life should have a sunsetting process defined, including communication to all potential users and a termination date</li> </ul>"},{"location":"architecture/adr/ADR-001_use_adrs/","title":"Use ADRs to document architecture decisions","text":""},{"location":"architecture/adr/ADR-001_use_adrs/#context","title":"Context","text":"<p>When architecture decisions are taken the context in which they are agreed gets lost over time, either because the developers that drove the decision leave the team or because over time the developers involved forget the exact circumstances that led to that decision.</p>"},{"location":"architecture/adr/ADR-001_use_adrs/#decision","title":"Decision","text":"<p>Architecture decisions agreed with the whole team should be documented using ADR format used here in our documentation.</p>"},{"location":"architecture/adr/ADR-001_use_adrs/#consequences","title":"Consequences","text":"<ul> <li>It should help documenting the context in which an architecture decision is taken</li> <li>It should help as record for future developers to understand certain architecture features of the system</li> <li>It should serve as documentation for future record to help remembering the reasoning behind an architecture decision</li> </ul>"},{"location":"architecture/adr/ADR-002_metrics_monitoring/","title":"Observability/Monitoring tool - push vs pull","text":""},{"location":"architecture/adr/ADR-002_metrics_monitoring/#context","title":"Context","text":"<p>ADEO/LMFR customer has order UX monitoring requirement and Cyncly has separate PSR - Performance, Security and Reliability evaluation tasks. Considering datadog as monitoring tool for infrastructure, application logs, tracing, etc. this could bring consistent experience to engineers and other end users. </p>"},{"location":"architecture/adr/ADR-002_metrics_monitoring/#decision","title":"Decision","text":"<p>Push based metrics collector such as datadog or similar could satisfy monitoring requirement as it tends to be easy setup compared with pull model (like prometheus - considering short live application monitoring setup complexity with pushgateway server) and relatively small size of logs, metrics, etc which generated.   </p> <p>Having said that we would review our monitoring toolsets when we need to scale monitoring requirements.</p>"},{"location":"architecture/adr/ADR-002_metrics_monitoring/#consequences","title":"Consequences","text":"<ul> <li>There could be latency on push model when large amount of telemetry data are routing. </li> <li>Due to latency, real-time monitoring experiences could be impacted and critical alerts can't be delivered in timely manner.</li> </ul>"},{"location":"architecture/adr/ADR-002_monitoring_tool_push_vs_pull/","title":"Monitoring tool - push vs pull","text":""},{"location":"architecture/adr/ADR-002_monitoring_tool_push_vs_pull/#context","title":"Context","text":"<p>Datadog has been proposed by ADEO/LMFR customer and Cyncly has separate PSR - Performance, Security and Reliability assessment ongoing task. Considering datadog as monitoring tool for infrastructure, application logs, tracing, etc. this could bring consistent experience to engineers and other end users. </p>"},{"location":"architecture/adr/ADR-002_monitoring_tool_push_vs_pull/#decision","title":"Decision","text":"<p>Push based metrics collector such as datadog or similar could satisfy monitoring requirement as it tends to be easy setup compared with pull model (like prometheus) considering short live application complexity and relatively small size of logs, metrics, etc that generate.   </p> <p>Having said that we would review our monitoring toolsets when we need to scale this requirement.</p>"},{"location":"architecture/adr/ADR-002_monitoring_tool_push_vs_pull/#consequences","title":"Consequences","text":"<ul> <li>There could be latency on push model when large amount of data are collected. </li> <li>Due to latency, real-time monitoring experiences would be impacted.</li> </ul>"},{"location":"architecture/adr/ADR-003_telemetry/","title":"ADR 003 telemetry","text":""},{"location":"architecture/adr/ADR-003_telemetry/#description","title":"Description","text":"<p>Focus on generation, collection, management and export of telemetry data such as traces, metrics, logs.</p>"},{"location":"architecture/adr/ADR-003_telemetry/#desire-outcome-or-benefits","title":"Desire outcome or benefits","text":"<p>Create visualization out of telemetry data to meet monitoring ~~and observability~~ requirements on latency, traffic, errors and saturation.</p>"},{"location":"architecture/adr/ADR-003_telemetry/#business-requirement","title":"Business requirement","text":"<p>Analyzing long term trends How big is my database and how fast is it growing? How quickly is my daily-active user count growing?</p> <p>Comparing over time or experiment groups  Are queries fast? How much better is my redis hit rate with an extra node? Is my site slower than it was last week?</p> <p>alerting - something is broken, and somebody needs to fix it right now! Or, something might break soon, so somebody should look soon. </p> <p>A bashboards should answer basic questions about your service, and normally include some form of latency of success and latency of failed requests, traffic, errors, saturation </p> <p>Conducting ad hoc retrospective analysis(i.e., debugging) Our latency just shot up; what else happened around the same time?</p>"},{"location":"architecture/adr/ADR-003_telemetry/#in-scope","title":"In scope","text":"<p>Black-box monitoring - including UX monitoring White-box monitoring </p>"},{"location":"architecture/adr/ADR-003_telemetry/#preconditions","title":"Preconditions","text":""},{"location":"architecture/adr/ADR-003_telemetry/#constrainsts","title":"Constrainsts","text":""},{"location":"architecture/adr/ADR-003_telemetry/#assumptions","title":"Assumptions","text":"<p>Avoid any situation that requires someone to stare at a screen to watch for problems</p>"},{"location":"architecture/adr/ADR-003_telemetry/#reference","title":"Reference","text":"<p>opentelemetry application-insights https://sre.google/</p>"},{"location":"architecture/adr/ADR-003_telemetry/#business-values","title":"Business values","text":"<p>monitor key business and performance indicators? PO item </p>"},{"location":"external_services/","title":"External services","text":"<p>These are external services used by our products which are provided by an external company.</p> <p>See also:</p> <ul> <li>Internal services</li> <li>Tooling</li> </ul>"},{"location":"external_services/github/","title":"GitHub","text":"<p>This is our repository for the team on GitHub:</p> <ul> <li>IS 7 Github team</li> </ul>"},{"location":"external_services/github/#git-settings","title":"Git Settings","text":"<p>Everyone that commits to git should have their username (real name, not GitHub username) / email address setup in the Git settings to easier find people to contact:  </p> <pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email \"youremail@cyncly.com\"\n</code></pre> <p>To confirm or check before</p> <pre><code>git config --list\n</code></pre> <p>We use the <code>rebase</code> option when pulling changes from remote to avoid unnecessary merge commits.</p> <p>This is not about git rebase but only about how to incorporate remote changes with a git pull --rebase</p> <p>This is what happens in IntelliJ IDEA when you do a \"Git -&gt; Update project\" in the morning (<code>CTRL t</code>).</p> <p>Merging a pull request into master (e.g. via GitHub) will still be a regular merge commit.</p> <p>There are two ways to make this configuration permanent: 1. IntelliJ IDEA: Settings -&gt; Version Control -&gt; Git -&gt; Update method: \"Rebase\" or when updating the project, choose <code>rebase ...</code> 1. git CLI: Update git config in home directory <code>~/.gitconfig</code>:</p> <pre><code>[pull]\n  rebase=true\n</code></pre>"},{"location":"external_services/github/#integrations","title":"Integrations","text":""},{"location":"external_services/github/#sentry","title":"Sentry","text":"<ul> <li>Connect from Sentry to GitHub</li> <li>see our Sentry documentation</li> </ul>"},{"location":"external_services/github/#slack","title":"Slack","text":"<ul> <li>Can notify about pull requests, commits, ...</li> <li>We use it to notify about status changes for pull requests (new, merged)</li> </ul>"},{"location":"external_services/github/#configuration","title":"Configuration","text":""},{"location":"external_services/github/#github-dependabot","title":"GitHub Dependabot","text":"<p>We use the dependabot to keep dependencies for non-Kotlin projects up-to-date. </p> <p>See Dependency Updates / Dependabot for details.</p>"},{"location":"external_services/github/#github-actions","title":"GitHub Actions","text":"<p>We use the Actions to run tests or simple non-deployment tasks. The Workflows are defined under <code>.github/workflows</code> in each repository</p> <ul> <li>Actions can consist of predefined or own / scripted steps</li> </ul>"},{"location":"external_services/sentry/","title":"Sentry","text":""},{"location":"external_services/team_comms/","title":"MS Team","text":""},{"location":"external_services/team_comms/#channels","title":"Channels","text":""},{"location":"internal_services/","title":"Internal services","text":""},{"location":"internal_services/vault/","title":"Vault","text":"<p>All secrets are centrally stored in Vault. (Do not store secrets in git!)</p>"},{"location":"services/","title":"Services","text":"<p>We are providing these different services in/around accessing SAP.</p>"},{"location":"team/","title":"Team","text":"<p>Here is documentation relevant for our team.</p>"},{"location":"team/bug_policy/","title":"Zero Bug Policy","text":"<p>quote from The Zero Bug Policy - Kevin Sookocheff</p>"},{"location":"team/bug_policy/#what-is-the-zero-bug-policy","title":"What is the Zero Bug Policy?","text":"<p>A Zero Bug Policy is simple. All bugs take priority over all new feature development or improvements. That\u2019s it. There is nothing more.</p> <p>An important corollary of this approach is that there is no such thing as bug priority, critical bugs, or minor bugs. An issue is either a bug or it isn\u2019t. And if it is a bug, you need to fix it before doing other work.</p>"},{"location":"team/bug_policy/#categories","title":"Categories","text":"<p>The category description below is from The Zero Bug Policy - Kevin Sookocheff</p>"},{"location":"team/bug_policy/#critical-issues","title":"Critical Issues","text":"<p>A critical issue is like the shop being on fire. If you don\u2019t put out the fire, you will no longer have a shop!</p> <p>Classification example: Consumers are no longer receiving the value they are entitled to, or money / time is being wasted at an unacceptable rate.</p> <p>Resolution example: Stop what you\u2019re doing, and fix the issue immediately.</p>"},{"location":"team/bug_policy/#bugs","title":"Bugs","text":"<p>Bugs are like water leaks. If you leave them too long, they can spoil your merchandise and slow down your business.</p> <p>Classification example: The system is not behaving as specified, but consumers are able to receive the value they\u2019re entitled to; or the rate of money / time wasted resulting from the issue is acceptable for the short-term.</p> <p>Resolution example: Finish what you\u2019re doing, and then fix it.</p>"},{"location":"team/bug_policy/#features","title":"Features","text":"<p>Everything which is not a Critical Issue or a Bug, e.g. a new functionality that does not yet exist in the system or an enhancement to an existing functionality or system.</p>"},{"location":"team/bug_policy/#process-for-new-tickets","title":"Process for new tickets","text":"<p>Every new ticket will be assigned one of these categories:</p> <ul> <li>Critical Issue: type \"Bug\" with priority \"Blocker\"</li> <li>Bug: type \"Bug\" with another priority than \"Blocker\"</li> <li> <p>Feature: type \"Story\"</p> </li> <li> <p>Critical Issues: topmost swim lane</p> </li> <li>Bugs: next swim lane below</li> <li>Features: last swim lane</li> </ul>"},{"location":"team/bug_policy/#reclassification","title":"Reclassification","text":"<p>We can always reclassify bugs when we learn and understand the impact or cost of a bug better. This allows us to continually readjust and adapt expectation vs reality, while maintaining a structured delivery approach that puts our team's quality standards first.</p>"},{"location":"team/bug_policy/#resources","title":"Resources","text":"<ul> <li>short read: The Zero Bug Policy - Kevin Sookocheff</li> <li>longer read: Zero-Bug Software Development</li> </ul>"},{"location":"team/onboarding/","title":"Onboarding of new colleagues","text":""},{"location":"team/ways_of_working/","title":"Ways of Working","text":""},{"location":"team/ways_of_working/#daily-stand-up-meeting","title":"Daily stand-up meeting","text":""},{"location":"team/ways_of_working/#weekly-care-taking","title":"Weekly Care Taking","text":""},{"location":"team/ways_of_working/#rotation-and-daily-assignment","title":"Rotation and daily assignment","text":""},{"location":"team/ways_of_working/#tasks","title":"Tasks","text":""},{"location":"team/ways_of_working/#live-deployments-are-not-gated-by-manual-intervention","title":"Live deployments are not gated by manual intervention","text":""},{"location":"team/ways_of_working/#requirements-to-enable-this","title":"Requirements to enable this","text":""},{"location":"team/ways_of_working/#every-team-member-is-responsible-for-the-quality-of-the-product","title":"Every team member is responsible for the quality of the product.","text":""},{"location":"team/ways_of_working/#database-changes-must-be-backward-compatible","title":"Database changes must be backward compatible","text":"<p>TODO</p>"},{"location":"team/ways_of_working/#prefer-to-fix-forward-over-rollback","title":"Prefer to fix forward over rollback","text":"<p>TODO</p>"},{"location":"team/ways_of_working/#we-have-confidence-in-our-automated-tests","title":"We have confidence in our automated tests.","text":"<p>If a live deployment leads to a bug, it reveals that we are missing a test. As part of the bug fix it is essential to add a test which covers the bug and protects us from this regression to happen again.</p>"},{"location":"team/ways_of_working/#we-have-confidence-in-our-monitoring-and-alerting","title":"We have confidence in our monitoring and alerting.","text":"<p>If a live deployment leads to a bug this is ideally discovered by the team itself based on the monitoring and alerting. Less good, but also possible, is that the bug is reported to the team from outside. As part of the bug fix we will check if there is a gap in our monitoring and alerting which would have alerted us about the bug as early as possible.</p>"},{"location":"team/ways_of_working/#we-believe-blameless-postmortems-are-an-essential-part-of-a-learning-culture","title":"We believe blameless postmortems are an essential part of a learning culture.","text":""},{"location":"team/ways_of_working/#code","title":"Code","text":""},{"location":"team/ways_of_working/#git","title":"Git","text":"<ul> <li>Have proper commit messages<ul> <li>guideline: The seven rules of a great Git commit message</li> </ul> </li> <li>Use these git settings<ul> <li>Identify yourself for your team-mates</li> <li>Use <code>git pull --rebase</code> to avoid unnecessary merge commits </li> <li>Example: \"CBS-111: Add tests for American Express Centurion Card\"</li> </ul> </li> </ul>"},{"location":"team/ways_of_working/#style-coding-convention","title":"Style / coding convention","text":"<ul> <li>Javascript / Node.JS</li> <li>Javascript / Node.JS</li> </ul>"},{"location":"tech/","title":"Technology","text":"<p>Here you can find information about the different technologies we use. Coding conventions, tech stacks, and more.</p>"},{"location":"tech/#languages","title":"Languages","text":"<p>We use currently these programming languages in our services:</p> <ul> <li>.NET</li> <li>Javascript</li> </ul>"},{"location":"tech/#todos","title":"ToDos","text":"<ul> <li>Add stuff about languages</li> <li>Describe tech stacks</li> <li>Info about Microsoft Azure</li> <li>Infos on testability &amp; unit tests </li> </ul>"},{"location":"tech/github-copilot/","title":"AI services","text":"<p>Understanding AI service such as Github Copilot, OpenAI, ChatGPT in business &amp; career development for our daily work to solve real world business problems is revolutionary. </p>"},{"location":"tech/github-copilot/#github-copilot-assessment","title":"Github Copilot assessment","text":"<ul> <li>AI co-pair programming </li> </ul>"},{"location":"tech/github-copilot/#unlocking-the-potential-of-copilot","title":"Unlocking the potential of Copilot","text":"<ul> <li>Easily build boilerplate code</li> <li>Create scaffold for structure of project</li> <li>Optional (setup virtualenv) etc.</li> </ul>"},{"location":"tech/github-copilot/#ecosystem","title":"Ecosystem","text":"<ul> <li>Codespaces - developer runtime environment</li> <li>DevContainer - Get exact development environment that can be shared other people </li> </ul>"},{"location":"tech/github-copilot/#enabling-productive-ai-pair-programming-with-copilot","title":"Enabling productive AI pair programming with Copilot","text":"<p>Codespaces is critical component  Prebuilt codespaces  * Github Copilot ~~Nightly~~ * Github Copilot Labs - prototype and swap from one language to another * Github Copilot cli * GIthub Copilot chat</p>"},{"location":"tech/github-copilot/#2fa","title":"2FA","text":"<p>https://docs.github.com/en/authentication/troubleshooting-ssh/error-permission-denied-publickey </p>"},{"location":"tech/github-copilot/#metrics-definitions","title":"Metrics definitions","text":"<p>Velocity and throughput metrics</p> <p>Throughput is a core measure of \u2018output\u2019 over time for Scrum teams - and can be calculated in tickets, story points, pull requests, builds or value points. This can be expressed as a percentage increase. </p> <p>Sprint Velocity considers the rate of work achieved within a sprint and how it varies over time.  It can be calculated in tickets or story points. This would be a key metric when considering the impact of GitHub Copilot. </p> <p>Time to value</p> <p>Cycle Time is a core agile software delivery metric which tracks an organisation\u2019s ability to deliver software early and often.  It calculates the time taken to deliver an increment of software from dev start to deployment.  The shorter the Cycle Time, the shorter the feedback loops, hence the quicker the organisation is going to receive new features and respond to customer needs.  This is a vital KPI when assessing technology delivery efficiency. </p> <p>Code Cycle Time typically accounts for 20-30% of overall Cycle Time. It calculates the average time taken from a pull request (PRs) opening until it is merged/closed. The bulk of this time is usually spent during the approval process.  In theory, GitHub CoPilot enables quicker, easier development. Therefore, developers should have greater availability to review each other\u2019s PRs. If code quality is improved, then the outcome of the reviews should result in fewer changes requested and an approval time.</p> <p>Quality</p> <p>Escaped Defects is a simple but effective measure of overall software delivery quality.  It can be tracked in numerous ways, but most involve tracking defects by criticality/priority.  Any analysis of delivery efficiency pre/post the implementation of GitHub Copilot should include consideration of Escaped Defect rates as it would be a poor trade-off to increase velocity and \u2018productivity\u2019 at the expense of quality.   </p> <p>Build Failure Rate identifies the percentage of builds which fail and the overall risk this poses to a team working productively. Notable changes to the failure rate after implementing GitHub Copilot indicate that code quality may be impacted. </p> <p>Dependencies</p> <p>Sprint Target Completion tracks the percentage of the sprint goals achieved each cycle. \u2018Scrum Teams\u2019 and \u2018Sprints\u2019 are the basic building blocks of Scrum Agile software delivery.  If Scrum Teams consistently deliver their Sprint goals, Agile software delivery becomes relatively dependable, enabling the prediction of delivery outcomes across multiple teams and longer time periods.  Scrum team predictability is, therefore, a critical success criterion in Agile software delivery. If GitHub Copilot can improve the likelihood of a team delivering their tickets faster and with fewer bugs, then this is a major contributor to the overall improvement in effectiveness. </p> <p>Developer Satisfaction</p> <p>eNPS tracks employee satisfaction and loyalty within teams and organisations. An employee NPS makes this straightforward to validate and quantify. Although an important factor of productivity measurement, it shouldn\u2019t be viewed in isolation from the other metrics when quantifying overall developer productivity.  The above are some examples of relevant metrics to consider when analysing the impact of GitHub Copilot on delivery productivity.  The key is to take a balanced set of metrics that holistically considers software delivery a complex process. </p>"},{"location":"tech/javascript/","title":"Javascript","text":""},{"location":"tech/javascript/#conventions","title":"Conventions","text":"<ul> <li>Coding Conventions ??? </li> <li>Use Prettier code formatter<ul> <li>The projects have a <code>.prettierrc</code> configuration file</li> <li>Enable in IDE to use Prettier for formatting Javascript code</li> <li>Activate to format on save</li> <li>The code will look the same for everyone</li> <li>Reduces potential issues with Git commits / merges</li> </ul> </li> </ul>"},{"location":"tooling/","title":"Tooling","text":"<p>Internal tools used by our products. These tools are deployed and maintained by the IS 7 team itself.</p>"},{"location":"tooling/dependency-update-check/","title":"Dependency Updates","text":""},{"location":"tooling/dependency-update-check/#github-dependabot","title":"GitHub Dependabot","text":""},{"location":"tooling/dependency-update-check/#regular-checks","title":"Regular checks","text":""},{"location":"tooling/documentation/","title":"Documentation","text":"<p>We are using mkdocs to generate our documentation. The documentation pages themselves are written using Markdown syntax.</p>"},{"location":"tooling/github-copilot/","title":"Github Copilot - AI assistant to partner with developers","text":""},{"location":"tooling/github-copilot/#impact-factor","title":"Impact factor","text":"<p>augment developer capabilities, enable them to be more productivity, reduce manual tasks and help them to focus on interesting work. </p>"},{"location":"tooling/github-copilot/#prompt-enginneering","title":"Prompt enginneering","text":"<ul> <li>Understanding of inputs(task, question, information), outputs and parameters </li> </ul>"},{"location":"tooling/github-copilot/#use-cases","title":"Use cases","text":"<ul> <li>Brainstroming - generates ideas and drafts </li> <li>Task management and desicion making </li> <li>Content generation: Blogs, articles and reports </li> <li>Task delegation and project management</li> </ul>"},{"location":"tooling/github-copilot/#ethics-and-considerations","title":"Ethics and considerations","text":"<ul> <li>Privacy and data security - Copilot asked for permission to allow MS to scan on end user codebase</li> <li>Responsibility and future work</li> <li>Average skills cannot produce more than average result</li> <li>Missing out on opportunities </li> <li>Optimal outputs is through evaluation and iteratives </li> <li>Manage copilot responsefully </li> <li>Inclusive language </li> </ul>"},{"location":"tooling/github-copilot/#define-problems","title":"Define problems","text":"<ul> <li>Lack of developer standard</li> <li>Security concerns </li> <li>Learning and development </li> <li>Automation </li> <li>Quality matrix  </li> </ul>"},{"location":"tooling/github-copilot/#set-goals-metrics-values-from-copilot","title":"Set goals (metrics) / values from copilot","text":"<ul> <li>Productivity<ul> <li>DORA Metrics <ul> <li>Increase (# no. of) deployment frequency - as of today, frequency is in between once per week to one per month</li> <li>Increase (# no. of) lead time for changes </li> <li>Reduce (in %) change failure rate  </li> <li>MTTR - Reduce (# no. of) defect that impact users </li> </ul> </li> </ul> </li> <li>Education - individual learner; improve learning journey since, copilot tells learner what to do /teaching assistant for both new and experience programmers get to know multiple solutions for one problem.</li> <li>Define developer standards </li> <li>quality - optimize query, algorithm, secure code </li> <li>Reduce bug </li> <li>Fast KT </li> <li>GitHub Copilot suggestions more secure hence, developer can avoid common vulnerable coding patterns including SQL injections, path injections, hardcoded credentials, etc. </li> <li>Easy on migration journey </li> <li>Developer satisfaction (qualitative)</li> <li>Stories burnt (in %)</li> <li>Code review </li> <li>Code structure, standards</li> </ul> <p>|  | | | :-----:|:-----:|:-----:|:-----:|  |  |Metrics for CoPilot Assessment|   |Qualitative|Developer Satisfaction/Developer Survey|Perceptual measures about code reviews can reveal whether developers view the work in a good or bad light\u2014for example if they present learning, mentorship, or opportunities to shape the codebase. With CoPilot does developer spend more time on high end coding effort rather than writing repeated codes or spending time on figuring out the design patterns?  |Quantitative|Story Point Shipped|# Commits, # Code Reviews. We need to give few quarters of time to find out whether # Story points shipped by developer in a Sprint increases. Also does SP assigned to a story reduces which is a measure of efficience increase.  | Qualitative|Code Review velocity and quality|Code-review velocity captures the speed of reviews; because this can reflect both how quickly an individual completes a review and the constraints of the team, it is both an individual- and a team-level metric. Also with help of copilot does quality of code review comments improves i.e it talks more about logic and domain comments rather than code structure and documentation.   | |4|Code Structure improvement|Can copilot help in ensuring that developers structire the code in similar way which makes it easier for other developers to understand? Also if CoPilot generates the boiler plate code so how much is efficiency gain here.  | |5|Code Standardization|   | |6|Quality of Documentation|Does CoPilot generates the automated comments for different methods and generate clear documentation thus saving developer time as well as ensure that code is easy to understand and KT will take lesser time due to good documentation  | |7|Knowledge Transfer|   | |8|Auto generation of unit test cases - Code testing| </p>"},{"location":"tooling/github-copilot/#plan-your-concepts","title":"Plan your concepts","text":""},{"location":"tooling/github-copilot/#create-a-wg-working-group","title":"Create a WG working group","text":"<p>Rakesh, Pandurang, Luis, Johannes, Jestha</p>"},{"location":"tooling/github-copilot/#build-prototype","title":"Build prototype","text":"<ul> <li>Creating C#, .NET scaffold for structure of project using Copilot </li> <li>Replicate the effort for other tech stack.</li> <li>Easy build up boilerplate or script - using Gihub Copilot cli extension </li> </ul>"},{"location":"tooling/github-copilot/#dedicate-enough-resources","title":"Dedicate enough resources","text":"<ul> <li>Github ecosystem available</li> </ul>"},{"location":"tooling/github-copilot/#evaluate-results","title":"Evaluate results","text":"<ul> <li>Evaluate Github Copilot ~~Nightly~~ </li> <li>Analyze co-pair programming using Github Copilot chat extension </li> <li>Translate between programming language using Github Copilot lab </li> <li>Evaluated regex pattern </li> <li>Suggested code may not work or even make sense</li> </ul>"},{"location":"tooling/github-copilot/#lesson-learned-based-on-assessment-done","title":"Lesson learned (based on assessment done)","text":""},{"location":"tooling/github-copilot/#risk-and-tolerance","title":"Risk and tolerance","text":""},{"location":"tooling/github-copilot/#guidelines","title":"Guidelines","text":"<ul> <li>Ensure suitability - testing, IP scanning, check for security vulnerabilities </li> <li>Don't compile before code is reviewed</li> <li>Suppress public code suggestions</li> <li>Developers are always in charge of - test, review and critical examination</li> <li>Developer survey</li> </ul>"},{"location":"tooling/github-copilot/#administration","title":"Administration","text":""},{"location":"tooling/owasp-dependency-check/","title":"OWASP","text":"<p>We monitor the libraries that our services use for potential known and published vulnerabilities. </p>"},{"location":"tooling/owasp-dependency-check/#regular-checks","title":"Regular checks","text":""},{"location":"tooling/owasp-dependency-check/#report","title":"Report","text":""},{"location":"tooling/owasp-dependency-check/#failing-pipeline","title":"Failing pipeline","text":""},{"location":"tooling/owasp-dependency-check/#suppression","title":"Suppression","text":"<p>Our goal is to have no suppression without a good reason, and to detail those reasons.</p> <p>If the pipeline reports a false positive, it needs to be suppressed by adding a suppression rule in <code>etc/owasp-security-checks/owasp-suppressions.xml</code>. The HTML report contains buttons to generate the needed suppression rule.</p>"},{"location":"tooling/owasp-dependency-check/#timeouts","title":"Timeouts","text":"<p>We put all suppression on a timeout (e.g. three month) and review them after that. This also keeps the file from growing unlimited.</p>"},{"location":"tooling/security-scan/","title":"Security Scan","text":"<p>We scan our services for any vulnerabilities through a web vulnerability scanner. </p>"},{"location":"tooling/security-scan/#how-can-you-log-in-and-start-using-it","title":"How can You log in and start using it?","text":""},{"location":"tooling/security-scan/#how-can-this-be-beneficial-for-our-development","title":"How can this be beneficial for our development?","text":"<p>If any project has security vulnerabilities exploited by attackers, it can cause harm to the business, revenue loss, reputation damage etc. We are all responsible for the security of the products that we are developing.</p>"},{"location":"tooling/security-scan/#secured-applications","title":"Secured Applications","text":""},{"location":"tooling/security-scan/#integration-with-halfpipe","title":"Integration with halfpipe","text":"<p>We haven't set up the pipeline for the security scan yet.  </p>"},{"location":"tooling/security-scan/#report","title":"Report","text":""}]}